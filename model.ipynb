{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximizing <span style=\"color:red\"> Stock Portfolio ROI </span> using <span style=\"color:blue\"> Deep Learning </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Portfolio of stocks.\n",
    "- Every stock goes on a sequence of increasing or decreasing for X (fixed) days straight.\n",
    "- Each sequence is linear, w/ a random fixed % change $\\in (-1,1)$, with Gaussian noise added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(num_stocks, num_days):\n",
    "    starting_price = 500.\n",
    "    seq_length = 5\n",
    "    data = np.array([[1 for stock in range(num_stocks)]])*starting_price\n",
    "    labels = np.zeros(num_stocks+1)\n",
    "    for _ in range(int(num_days/seq_length)):\n",
    "        percent_change = 2.*np.random.rand(num_stocks) - 1.\n",
    "        new_label = np.zeros(num_stocks+1)\n",
    "        if np.max(percent_change) > 0:\n",
    "            new_label[np.argmax(percent_change)] = 1\n",
    "        else:\n",
    "            new_label[-1] = 1\n",
    "        for day in range(seq_length):\n",
    "            price_change = 1 + 0.01*percent_change + 0.05/100.*np.random.randn(4)\n",
    "            data = np.vstack((data,data[-1]*price_change))\n",
    "            labels = np.vstack((labels, new_label))\n",
    "    return data, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_toy, Y_train_toy = generate_dataset(4, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('X_train_toy',X_train_toy)\n",
    "np.save('Y_train_toy',Y_train_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_toy = np.load('X_train_toy.npy')\n",
    "Y_train_toy = np.load('Y_train_toy.npy')\n",
    "\n",
    "mean = X_train_toy.mean(axis=0)\n",
    "std = X_train_toy.std(axis=0)\n",
    "\n",
    "X_train_norm = (X_train_toy - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "\n",
    "X_train_seq = []\n",
    "for batch_start in range(timesteps, X_train_norm.shape[0]):\n",
    "    X_train_seq.append(X_train_norm[batch_start-timesteps:batch_start,:])\n",
    "X_train_seq = np.vstack(([np.array([seq]) for seq in X_train_seq]))\n",
    "Y_train_seq = Y_train_toy[timesteps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_size = X_train_seq.shape[0]\n",
    "split = dataset_size//5\n",
    "\n",
    "X_test_seq = X_train_seq[:split]\n",
    "Y_test_seq = Y_train_seq[:split]\n",
    "X_train_seq = X_train_seq[split:]\n",
    "Y_train_seq = Y_train_seq[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 4\n",
    "nb_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(42, activation='relu'), input_shape=(timesteps, data_dim)))\n",
    "model.add(LSTM(42, return_sequences=True))\n",
    "model.add(LSTM(42, return_sequences=False))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5405 - categorical_accuracy: 0.7878     \n",
      "Epoch 2/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5382 - categorical_accuracy: 0.7784     \n",
      "Epoch 3/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5076 - categorical_accuracy: 0.7916     \n",
      "Epoch 4/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5120 - categorical_accuracy: 0.7979     \n",
      "Epoch 5/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5008 - categorical_accuracy: 0.8023     \n",
      "Epoch 6/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5147 - categorical_accuracy: 0.7866     \n",
      "Epoch 7/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5002 - categorical_accuracy: 0.7891     \n",
      "Epoch 8/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.5055 - categorical_accuracy: 0.7897     \n",
      "Epoch 9/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4749 - categorical_accuracy: 0.8085     \n",
      "Epoch 10/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4813 - categorical_accuracy: 0.8060     \n",
      "Epoch 11/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4792 - categorical_accuracy: 0.8148     \n",
      "Epoch 12/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4838 - categorical_accuracy: 0.8104     \n",
      "Epoch 13/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4844 - categorical_accuracy: 0.8110     \n",
      "Epoch 14/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4622 - categorical_accuracy: 0.8205     \n",
      "Epoch 15/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4594 - categorical_accuracy: 0.8104     \n",
      "Epoch 16/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4717 - categorical_accuracy: 0.8054     \n",
      "Epoch 17/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4690 - categorical_accuracy: 0.8092     \n",
      "Epoch 18/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4677 - categorical_accuracy: 0.8167     \n",
      "Epoch 19/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4523 - categorical_accuracy: 0.8249     \n",
      "Epoch 20/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4690 - categorical_accuracy: 0.8016     \n",
      "Epoch 21/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4511 - categorical_accuracy: 0.8186     \n",
      "Epoch 22/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4476 - categorical_accuracy: 0.8192     \n",
      "Epoch 23/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4805 - categorical_accuracy: 0.8123     \n",
      "Epoch 24/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4507 - categorical_accuracy: 0.8198     \n",
      "Epoch 25/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4461 - categorical_accuracy: 0.8117     \n",
      "Epoch 26/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4313 - categorical_accuracy: 0.8255     \n",
      "Epoch 27/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4210 - categorical_accuracy: 0.8299     \n",
      "Epoch 28/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4385 - categorical_accuracy: 0.8293     \n",
      "Epoch 29/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4380 - categorical_accuracy: 0.8267     \n",
      "Epoch 30/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4038 - categorical_accuracy: 0.8487     \n",
      "Epoch 31/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4145 - categorical_accuracy: 0.8286     \n",
      "Epoch 32/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4219 - categorical_accuracy: 0.8274     \n",
      "Epoch 33/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4294 - categorical_accuracy: 0.8336     \n",
      "Epoch 34/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4112 - categorical_accuracy: 0.8318     \n",
      "Epoch 35/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4151 - categorical_accuracy: 0.8336     \n",
      "Epoch 36/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4198 - categorical_accuracy: 0.8293     \n",
      "Epoch 37/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4125 - categorical_accuracy: 0.8380     \n",
      "Epoch 38/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4021 - categorical_accuracy: 0.8424     \n",
      "Epoch 39/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.4153 - categorical_accuracy: 0.8349     \n",
      "Epoch 40/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3949 - categorical_accuracy: 0.8449     \n",
      "Epoch 41/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3739 - categorical_accuracy: 0.8569     \n",
      "Epoch 42/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3775 - categorical_accuracy: 0.8481     \n",
      "Epoch 43/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3907 - categorical_accuracy: 0.8399     \n",
      "Epoch 44/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3954 - categorical_accuracy: 0.8418     \n",
      "Epoch 45/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3831 - categorical_accuracy: 0.8462     \n",
      "Epoch 46/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3864 - categorical_accuracy: 0.8512     \n",
      "Epoch 47/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3990 - categorical_accuracy: 0.8355     \n",
      "Epoch 48/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3828 - categorical_accuracy: 0.8512     \n",
      "Epoch 49/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3804 - categorical_accuracy: 0.8525     \n",
      "Epoch 50/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3823 - categorical_accuracy: 0.8506     \n",
      "Epoch 51/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3629 - categorical_accuracy: 0.8475     \n",
      "Epoch 52/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3830 - categorical_accuracy: 0.8506     \n",
      "Epoch 53/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3758 - categorical_accuracy: 0.8519     \n",
      "Epoch 54/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3654 - categorical_accuracy: 0.8544     \n",
      "Epoch 55/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3707 - categorical_accuracy: 0.8493     \n",
      "Epoch 56/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3502 - categorical_accuracy: 0.8575     \n",
      "Epoch 57/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3604 - categorical_accuracy: 0.8581     \n",
      "Epoch 58/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3495 - categorical_accuracy: 0.8562     \n",
      "Epoch 59/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3701 - categorical_accuracy: 0.8544     \n",
      "Epoch 60/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3327 - categorical_accuracy: 0.8726     \n",
      "Epoch 61/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3711 - categorical_accuracy: 0.8569     \n",
      "Epoch 62/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3505 - categorical_accuracy: 0.8657     \n",
      "Epoch 63/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3541 - categorical_accuracy: 0.8625     \n",
      "Epoch 64/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3589 - categorical_accuracy: 0.8519     \n",
      "Epoch 65/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3547 - categorical_accuracy: 0.8556     \n",
      "Epoch 66/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3408 - categorical_accuracy: 0.8632     \n",
      "Epoch 67/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3367 - categorical_accuracy: 0.8619     \n",
      "Epoch 68/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3468 - categorical_accuracy: 0.8625     \n",
      "Epoch 69/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3334 - categorical_accuracy: 0.8606     \n",
      "Epoch 70/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3303 - categorical_accuracy: 0.8694     \n",
      "Epoch 71/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3571 - categorical_accuracy: 0.8588     \n",
      "Epoch 72/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3270 - categorical_accuracy: 0.8707     \n",
      "Epoch 73/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3417 - categorical_accuracy: 0.8663     \n",
      "Epoch 74/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3190 - categorical_accuracy: 0.8688     \n",
      "Epoch 75/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3295 - categorical_accuracy: 0.8675     \n",
      "Epoch 76/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3161 - categorical_accuracy: 0.8763     \n",
      "Epoch 77/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3245 - categorical_accuracy: 0.8782     \n",
      "Epoch 78/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3202 - categorical_accuracy: 0.8694     \n",
      "Epoch 79/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3310 - categorical_accuracy: 0.8657     \n",
      "Epoch 80/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3320 - categorical_accuracy: 0.8619     \n",
      "Epoch 81/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.2988 - categorical_accuracy: 0.8788     \n",
      "Epoch 82/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3117 - categorical_accuracy: 0.8820     \n",
      "Epoch 83/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3255 - categorical_accuracy: 0.8726     \n",
      "Epoch 84/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3227 - categorical_accuracy: 0.8682     \n",
      "Epoch 85/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3050 - categorical_accuracy: 0.8832     \n",
      "Epoch 86/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3116 - categorical_accuracy: 0.8782     \n",
      "Epoch 87/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3239 - categorical_accuracy: 0.8732     \n",
      "Epoch 88/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3069 - categorical_accuracy: 0.8814     \n",
      "Epoch 89/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3276 - categorical_accuracy: 0.8638     \n",
      "Epoch 90/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3090 - categorical_accuracy: 0.8807     \n",
      "Epoch 91/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3180 - categorical_accuracy: 0.8669     \n",
      "Epoch 92/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.2991 - categorical_accuracy: 0.8801     \n",
      "Epoch 93/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3063 - categorical_accuracy: 0.8770     \n",
      "Epoch 94/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3021 - categorical_accuracy: 0.8751     \n",
      "Epoch 95/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3158 - categorical_accuracy: 0.8732     \n",
      "Epoch 96/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3147 - categorical_accuracy: 0.8738     \n",
      "Epoch 97/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.2818 - categorical_accuracy: 0.8851     \n",
      "Epoch 98/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.2810 - categorical_accuracy: 0.8939     \n",
      "Epoch 99/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.2979 - categorical_accuracy: 0.8782     \n",
      "Epoch 100/100\n",
      "1593/1593 [==============================] - 3s - loss: 0.3030 - categorical_accuracy: 0.8770     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120093050>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_seq, Y_train_seq, batch_size=50, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1593/1593 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89391086001255493"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict_proba(X_train_seq),axis=1)\n",
    "truth = np.argmax(Y_train_seq,axis=1)\n",
    "np.mean(predictions==truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30904522613065327"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict_proba(X_test_seq),axis=1)\n",
    "truth = np.argmax(Y_test_seq,axis=1)\n",
    "np.mean(predictions==truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_toy.h5')\n",
    "#model = load_model('model_toy.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for idx in glob.glob(\"data/*.csv\"):\n",
    "    if idx == 'data/S&P500.csv': continue\n",
    "    stock = np.genfromtxt(idx,skip_header=1,usecols=(0,1),delimiter=',',dtype=[\"S10\",\"f8\"])\n",
    "    data = np.zeros((stock.shape[0],2))\n",
    "    data[:,0] = np.array([datetime.datetime.strptime(entry[0], \"%Y-%m-%d\").date().timetuple().tm_yday for entry in stock])\n",
    "    data[:,1] = np.array([entry[1] for entry in stock])\n",
    "    dataset.append((idx,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_stocks = 4\n",
    "data_batches = []\n",
    "idxs = []\n",
    "\n",
    "for stock1 in range(0,len(dataset)):\n",
    "    for stock2 in range(stock1+1,len(dataset)):\n",
    "        for stock3 in range(stock2+1,len(dataset)):\n",
    "            for stock4 in range(stock3+1,len(dataset)):\n",
    "                size = np.min([dataset[stock1][1].shape[0],dataset[stock2][1].shape[0],dataset[stock3][1].shape[0],dataset[stock4][1].shape[0]])\n",
    "                data_batch = np.hstack((dataset[stock1][1][0:size,:],dataset[stock2][1][0:size,:],dataset[stock3][1][0:size,:],dataset[stock4][1][0:size,:]))\n",
    "                data_batches.append(data_batch)\n",
    "                if not idxs:\n",
    "                    idxs.append(data_batch.shape[0]-2)\n",
    "                else:\n",
    "                    idxs.append(idxs[-1] + data_batch.shape[0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label(current, future):\n",
    "    label = np.zeros(5) # [stock1, stock2, stock3, stock4, Cash]\n",
    "    profit = np.true_divide(future - current, current)\n",
    "    idx = np.argmax(profit)\n",
    "    if profit[idx] <= 0: idx = -1\n",
    "    label[idx] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_batches = []\n",
    "\n",
    "for batch in data_batches:\n",
    "    label_batch = np.zeros((batch.shape[0]-1,5))\n",
    "    for idx in range(batch.shape[0]-1):\n",
    "        current, future = batch[idx+1][[1,3,5,7]], batch[idx][[1,3,5,7]]\n",
    "        label_batch[idx] = label(current,future)\n",
    "    label_batches.append(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.vstack((batch[1:,:] for batch in data_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264809, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np.vstack(np.vstack((label for label in label_batch)) for label_batch in label_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264809, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('X_train',X_train)\n",
    "np.save('Y_train',Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train_norm = (X_train - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = Y_train.shape[1]\n",
    "T = 100\n",
    "X_train_seq = []\n",
    "Y_train_seq = []\n",
    "for i in range(len(idxs)):\n",
    "    if i == 0:\n",
    "        start_idx = 0\n",
    "    else:\n",
    "        start_idx = idxs[i-1] + 1\n",
    "    end_idx = idxs[i]\n",
    "    for j in range(start_idx + T - 1, end_idx+1):\n",
    "        tX = X_train_norm[j - (T - 1): j + 1]\n",
    "        tY = Y_train[j]\n",
    "        X_train_seq.append(tX[None,:,:])\n",
    "        Y_train_seq.append(tY[None,:])\n",
    "        del tX\n",
    "        del tY\n",
    "\n",
    "X_train_seq = np.concatenate(X_train_seq, axis=0)\n",
    "Y_train_seq = np.concatenate(Y_train_seq, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dim = 8\n",
    "timesteps = 100\n",
    "nb_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(42, activation='relu'), input_shape=(timesteps, data_dim)))\n",
    "model.add(LSTM(42, return_sequences=True))\n",
    "model.add(LSTM(42, return_sequences=False))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# model.fit(X_train_seq[:20], Y_train_seq[:20], batch_size=20, nb_epoch=20)\n",
    "#score = model.evaluate(X_test, Y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "  3900/252335 [..............................] - ETA: 2477s - loss: 1.5969 - categorical_accuracy: 0.2508"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_seq, Y_train_seq, batch_size=50, nb_epoch=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17999999999999999"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict_proba(X_train_seq[1000:1500,:,:]),axis=1)\n",
    "truth = np.argmax(Y_train_seq[1000:1500],axis=1)\n",
    "np.mean(predictions==truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
