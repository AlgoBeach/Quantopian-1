{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximizing <span style=\"color:red\"> Stock Portfolio ROI </span> using <span style=\"color:blue\"> Deep Learning </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Portfolio of stocks.\n",
    "- Every stock goes on a sequence of increasing or decreasing for X (fixed) days straight.\n",
    "- Each sequence is linear, w/ a random fixed % change $\\in (-1,1)$, with Gaussian noise added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(num_stocks, num_days):\n",
    "    starting_price = 500.\n",
    "    seq_length = 5\n",
    "    day_of_year = 0\n",
    "    data = np.array([np.append(np.array([1 for stock in range(num_stocks)])*starting_price,\n",
    "                               day_of_year)])\n",
    "    labels = np.zeros(num_stocks+1)\n",
    "    for _ in range(int(num_days/seq_length)):\n",
    "        percent_change = 2.*np.random.rand(num_stocks) - 1.\n",
    "        new_label = np.zeros(num_stocks+1)\n",
    "        if np.max(percent_change) > 0:\n",
    "            new_label[np.argmax(percent_change)] = 1\n",
    "        else:\n",
    "            new_label[-1] = 1\n",
    "        for day in range(seq_length):\n",
    "            price_change = 1 + 0.01*percent_change + .1/100.*np.random.randn(4)\n",
    "            day_of_year = (day_of_year+1)%365\n",
    "            new_data = np.append(data[-1,:-1]*price_change, day_of_year)\n",
    "            data = np.vstack((data, new_data))\n",
    "            labels = np.vstack((labels, new_label))\n",
    "    return data, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_toy, Y_train_toy = generate_dataset(4, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('X_train_toy',X_train_toy)\n",
    "np.save('Y_train_toy',Y_train_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_toy = np.load('X_train_toy.npy')\n",
    "Y_train_toy = np.load('Y_train_toy.npy')\n",
    "\n",
    "mean = X_train_toy.mean(axis=0)\n",
    "std = X_train_toy.std(axis=0)\n",
    "\n",
    "X_train_norm = (X_train_toy - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  420.61761852,  1163.27369089,  1182.39914984,   405.73446034,\n",
       "          179.21015797]),\n",
       " array([ 133.54786501,  508.11372297,  352.16508521,   83.10877008,\n",
       "         104.6781473 ]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timesteps = 10\n",
    "\n",
    "X_train_seq = []\n",
    "for batch_start in range(timesteps, X_train_norm.shape[0]):\n",
    "    X_train_seq.append(X_train_norm[batch_start-timesteps:batch_start,:])\n",
    "X_train_seq = np.vstack(([np.array([seq]) for seq in X_train_seq]))\n",
    "Y_train_seq = Y_train_toy[timesteps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_size = X_train_seq.shape[0]\n",
    "split = dataset_size//5\n",
    "\n",
    "X_test_seq = X_train_seq[:split]\n",
    "Y_test_seq = Y_train_seq[:split]\n",
    "X_train_seq = X_train_seq[split:]\n",
    "Y_train_seq = Y_train_seq[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = 5 # [stock1, stock2, stock3, stock4, day_of_year]\n",
    "nb_classes = 5 # [buy1, buy2, buy3, buy4, sell_all]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(42, activation='relu'), input_shape=(timesteps, data_dim)))\n",
    "model.add(LSTM(42, return_sequences=True))\n",
    "model.add(LSTM(42, return_sequences=False))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3993/3993 [==============================] - 8s - loss: 1.5147 - categorical_accuracy: 0.2695     \n",
      "Epoch 2/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.4803 - categorical_accuracy: 0.3023     \n",
      "Epoch 3/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.4540 - categorical_accuracy: 0.3208     \n",
      "Epoch 4/10\n",
      "3993/3993 [==============================] - 8s - loss: 1.4282 - categorical_accuracy: 0.3428     \n",
      "Epoch 5/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.4076 - categorical_accuracy: 0.3554     \n",
      "Epoch 6/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.3832 - categorical_accuracy: 0.3711     \n",
      "Epoch 7/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.3603 - categorical_accuracy: 0.3944     \n",
      "Epoch 8/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.3365 - categorical_accuracy: 0.4097     \n",
      "Epoch 9/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.3195 - categorical_accuracy: 0.4155     \n",
      "Epoch 10/10\n",
      "3993/3993 [==============================] - 7s - loss: 1.3035 - categorical_accuracy: 0.4185     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x113ede910>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_seq, Y_train_seq, batch_size=50, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3993/3993 [==============================] - 2s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43901828199348858"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict_proba(X_train_seq),axis=1)\n",
    "truth = np.argmax(Y_train_seq,axis=1)\n",
    "np.mean(predictions==truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/998 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28356713426853708"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict_proba(X_test_seq),axis=1)\n",
    "truth = np.argmax(Y_test_seq,axis=1)\n",
    "np.mean(predictions==truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_toy.h5')\n",
    "#model = load_model('model_toy.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for idx in glob.glob(\"data/*.csv\"):\n",
    "    if idx == 'data/S&P500.csv': continue\n",
    "    stock = np.genfromtxt(idx,skip_header=1,usecols=(0,1),delimiter=',',dtype=[\"S10\",\"f8\"])\n",
    "    data = np.zeros((stock.shape[0],2))\n",
    "    data[:,0] = np.array([datetime.datetime.strptime(entry[0], \"%Y-%m-%d\").date().timetuple().tm_yday for entry in stock])\n",
    "    data[:,1] = np.array([entry[1] for entry in stock])\n",
    "    dataset.append((idx,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_stocks = 4\n",
    "data_batches = []\n",
    "idxs = []\n",
    "\n",
    "for stock1 in range(0,len(dataset)):\n",
    "    for stock2 in range(stock1+1,len(dataset)):\n",
    "        for stock3 in range(stock2+1,len(dataset)):\n",
    "            for stock4 in range(stock3+1,len(dataset)):\n",
    "                size = np.min([dataset[stock1][1].shape[0],dataset[stock2][1].shape[0],dataset[stock3][1].shape[0],dataset[stock4][1].shape[0]])\n",
    "                data_batch = np.hstack((dataset[stock1][1][0:size,:],dataset[stock2][1][0:size,:],dataset[stock3][1][0:size,:],dataset[stock4][1][0:size,:]))\n",
    "                data_batches.append(data_batch)\n",
    "                if not idxs:\n",
    "                    idxs.append(data_batch.shape[0]-2)\n",
    "                else:\n",
    "                    idxs.append(idxs[-1] + data_batch.shape[0] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label(current, future):\n",
    "    label = np.zeros(5) # [stock1, stock2, stock3, stock4, Cash]\n",
    "    profit = np.true_divide(future - current, current)\n",
    "    idx = np.argmax(profit)\n",
    "    if profit[idx] <= 0: idx = -1\n",
    "    label[idx] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_batches = []\n",
    "\n",
    "for batch in data_batches:\n",
    "    label_batch = np.zeros((batch.shape[0]-1,5))\n",
    "    for idx in range(batch.shape[0]-1):\n",
    "        current, future = batch[idx+1][[1,3,5,7]], batch[idx][[1,3,5,7]]\n",
    "        label_batch[idx] = label(current,future)\n",
    "    label_batches.append(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.vstack((batch[1:,:] for batch in data_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264809, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np.vstack(np.vstack((label for label in label_batch)) for label_batch in label_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264809, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('X_train',X_train)\n",
    "np.save('Y_train',Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "X_train_norm = (X_train - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = Y_train.shape[1]\n",
    "T = 100\n",
    "X_train_seq = []\n",
    "Y_train_seq = []\n",
    "for i in range(len(idxs)):\n",
    "    if i == 0:\n",
    "        start_idx = 0\n",
    "    else:\n",
    "        start_idx = idxs[i-1] + 1\n",
    "    end_idx = idxs[i]\n",
    "    for j in range(start_idx + T - 1, end_idx+1):\n",
    "        tX = X_train_norm[j - (T - 1): j + 1]\n",
    "        tY = Y_train[j]\n",
    "        X_train_seq.append(tX[None,:,:])\n",
    "        Y_train_seq.append(tY[None,:])\n",
    "        del tX\n",
    "        del tY\n",
    "\n",
    "X_train_seq = np.concatenate(X_train_seq, axis=0)\n",
    "Y_train_seq = np.concatenate(Y_train_seq, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dim = 8\n",
    "timesteps = 100\n",
    "nb_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(42, activation='relu'), input_shape=(timesteps, data_dim)))\n",
    "model.add(LSTM(42, return_sequences=True))\n",
    "model.add(LSTM(42, return_sequences=False))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "# model.fit(X_train_seq[:20], Y_train_seq[:20], batch_size=20, nb_epoch=20)\n",
    "#score = model.evaluate(X_test, Y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "  3900/252335 [..............................] - ETA: 2477s - loss: 1.5969 - categorical_accuracy: 0.2508"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_seq, Y_train_seq, batch_size=50, nb_epoch=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17999999999999999"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict_proba(X_train_seq[1000:1500,:,:]),axis=1)\n",
    "truth = np.argmax(Y_train_seq[1000:1500],axis=1)\n",
    "np.mean(predictions==truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
